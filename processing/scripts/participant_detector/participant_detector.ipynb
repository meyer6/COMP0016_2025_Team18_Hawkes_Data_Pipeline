{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "# Participant/Expert Card Detector\n",

    "\n",

    "Detects \"Participant N\" / \"Expert N\" cards shown in video frames and outputs a table of timed appearances.\n",

    "\n",

    "**Pipeline:** `read frames → skip unchanged scenes → OCR → fuzzy match → group into sessions`\n",

    "\n",

    "1. **Frame reading**: Samples every Nth frame, downscaled to 480p grayscale. Frames in between are skipped with `grab()` to advance the video without decoding.\n",

    "2. **Scene change detection**: Consecutive frames are compared with `cv2.absdiff`. If the scene hasn't changed, OCR is skipped and the previous result is reused. During an active detection session, every frame is OCR'd for accurate timing.\n",

    "3. **OCR**: EasyOCR extracts text from each frame on the GPU, restricted to alphanumeric characters. A background thread prefetches upcoming frames so I/O and GPU inference overlap.\n",

    "4. **Fuzzy matching**: Extracted text is matched against \"participant\" / \"expert\" using Levenshtein distance with up to 3 edits tolerance to handle OCR errors.\n",

    "5. **Session grouping**: Consecutive detections are grouped into sessions. A session ends after `CARD_TIMEOUT_FRAMES` consecutive misses. The most common (type, number) pair per session is taken as the final label to filter out noise."

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:01:48.748499Z",
     "start_time": "2025-12-27T15:01:47.401362Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader([\"en\"], gpu=torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:01:48.752765Z",
     "start_time": "2025-12-27T15:01:48.748879Z"
    }
   },
   "outputs": [],
   "source": [
    "VIDEO_PATH = \"../../../datasets/videos/example5.avi\"\n",
    "\n",
    "FRAME_SKIP = 10\n",
    "CARD_TIMEOUT_FRAMES = 10\n",
    "SCENE_CHANGE_THRESHOLD = 5.0\n",
    "OCR_ALLOWLIST = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:01:48.759693Z",
     "start_time": "2025-12-27T15:01:48.754743Z"
    }
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if not s2:\n",
    "        return len(s1)\n",
    "\n",
    "    prev = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        curr = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            curr.append(min(prev[j + 1] + 1, curr[j] + 1, prev[j] + (c1 != c2)))\n",
    "        prev = curr\n",
    "\n",
    "    return prev[-1]\n",
    "\n",
    "\n",
    "def parse_card(text):\n",
    "    words = re.findall(r\"[A-Za-z]+|[0-9]+\", text)\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if len(word) < 5:\n",
    "            continue\n",
    "        d_p = levenshtein_distance(word.lower(), \"participant\")\n",
    "        d_e = levenshtein_distance(word.lower(), \"expert\")\n",
    "\n",
    "        if d_p <= 3 or d_e <= 3:\n",
    "            for j in range(i + 1, len(words)):\n",
    "                if words[j].isdigit():\n",
    "                    role = \"participant\" if d_p <= d_e else \"expert\"\n",
    "                    return (role, int(words[j]))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = seconds % 60\n",
    "    return f\"{h:02d}:{m:02d}:{s:06.3f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:01:48.763660Z",
     "start_time": "2025-12-27T15:01:48.759911Z"
    }
   },
   "outputs": [],
   "source": [
    "def prefetch(iterator, buffer=8):\n",
    "    # Background thread reads frames while main thread runs GPU OCR (both release GIL)\n",
    "    q = Queue(maxsize=buffer)\n",
    "\n",
    "    def fill():\n",
    "        for item in iterator:\n",
    "            q.put(item)\n",
    "        q.put(None)\n",
    "\n",
    "    Thread(target=fill, daemon=True).start()\n",
    "    while (item := q.get()) is not None:\n",
    "        yield item\n",
    "\n",
    "\n",
    "def read_frames(video_path, frame_skip):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if fps == 0 or total == 0:\n",
    "        cap.release()\n",
    "        raise ValueError(f\"Invalid video: fps={fps}, frames={total}\")\n",
    "\n",
    "    def frames():\n",
    "        n = 0\n",
    "        while True:\n",
    "            if n % frame_skip != 0:\n",
    "                if not cap.grab():\n",
    "                    break\n",
    "                n += 1\n",
    "                continue\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            if h > 480:\n",
    "                scale = 480 / h\n",
    "                frame = cv2.resize(frame, (int(w * scale), 480), interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            yield n, frame\n",
    "            n += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    return fps, total, frames()\n",
    "\n",
    "\n",
    "def ocr_frames(frames_iter, total_frames):\n",
    "    prev_frame = None\n",
    "    prev_result = None\n",
    "    in_session = False\n",
    "\n",
    "    for frame_num, img in prefetch(frames_iter):\n",
    "        if not in_session and prev_frame is not None:\n",
    "            if cv2.absdiff(prev_frame, img).mean() < SCENE_CHANGE_THRESHOLD:\n",
    "                prev_frame = img\n",
    "                yield frame_num, prev_result\n",
    "                continue\n",
    "\n",
    "        text = reader.readtext(img, detail=0, paragraph=True, allowlist=OCR_ALLOWLIST)\n",
    "        prev_result = parse_card(\" \".join(text) if isinstance(text, list) else text)\n",
    "        prev_frame = img\n",
    "        in_session = prev_result is not None\n",
    "\n",
    "        yield frame_num, prev_result\n",
    "\n",
    "\n",
    "def collect_sessions(ocr_iter, fps, total_frames):\n",
    "    detections = []\n",
    "    session_start = None\n",
    "    session_detections = []\n",
    "    misses = 0\n",
    "\n",
    "    sentinel = ((total_frames, None) for _ in range(CARD_TIMEOUT_FRAMES))\n",
    "\n",
    "    for frame_num, result in chain(ocr_iter, sentinel):\n",
    "        if result:\n",
    "            if session_start is None:\n",
    "                session_start = frame_num\n",
    "                session_detections = []\n",
    "            session_detections.append(result)\n",
    "            misses = 0\n",
    "\n",
    "        elif session_start is not None:\n",
    "            misses += 1\n",
    "            if misses >= CARD_TIMEOUT_FRAMES:\n",
    "                card_type, number = Counter(session_detections).most_common(1)[0][0]\n",
    "                start_sec = session_start / fps\n",
    "                end_sec = frame_num / fps\n",
    "\n",
    "                detections.append({\n",
    "                    \"type\": card_type,\n",
    "                    \"number\": number,\n",
    "                    \"start_time\": format_timestamp(start_sec),\n",
    "                    \"end_time\": format_timestamp(end_sec),\n",
    "                    \"duration_sec\": round(end_sec - start_sec, 2),\n",
    "                })\n",
    "\n",
    "                session_start = None\n",
    "                misses = 0\n",
    "\n",
    "    return pd.DataFrame(detections)\n",
    "\n",
    "\n",
    "def detect_cards(video_path):\n",
    "    fps, total_frames, frames = read_frames(video_path, FRAME_SKIP)\n",
    "    return collect_sessions(ocr_frames(frames, total_frames), fps, total_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:12:47.458109Z",
     "start_time": "2025-12-27T15:01:48.763860Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = detect_cards(VIDEO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T15:12:47.662856Z",
     "start_time": "2025-12-27T15:12:47.485145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>number</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>participant</td>\n",
       "      <td>12</td>\n",
       "      <td>00:01:51.667</td>\n",
       "      <td>00:01:52.333</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type  number    start_time      end_time  duration_sec\n",
       "0  participant      12  00:01:51.667  00:01:52.333          0.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(results_df) > 0:\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"No cards detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}