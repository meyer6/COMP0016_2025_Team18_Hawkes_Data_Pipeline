{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Classifier - Video Frame Classification\n",
    "\n",
    "Train a ResNet50 classifier to identify tasks from video frames and process videos to extract task timestamps.\n",
    "\n",
    "## Features\n",
    "- Transfer learning with pretrained ResNet50\n",
    "- Class imbalance handling with weighted loss\n",
    "- Temporal smoothing for video inference\n",
    "- CSV export of predictions and time ranges\n",
    "\n",
    "## Task Classes\n",
    "CameraTarget, ChickenThigh, CystModel, GloveCut, Idle, MovingIndividualAxes, RingRollercoaster, SeaSpikes, Suture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T15:23:17.723054Z",
     "start_time": "2025-12-28T15:23:17.674289Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T15:23:17.766594Z",
     "start_time": "2025-12-28T15:23:17.729732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_PATH = \"../../../datasets/tasks_classified/\"\n",
    "MODEL_DIR = \"../../../processing/models/\"\n",
    "\n",
    "# Training\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 0.0001\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Parallel Processing\n",
    "NUM_WORKERS = 8  # Parallel data loading (CPU cores to use)\n",
    "USE_MIXED_PRECISION = True  # Faster training on GPU (FP16)\n",
    "\n",
    "# Setup\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    \n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders with FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T15:23:18.014725Z",
     "start_time": "2025-12-28T15:23:17.771488Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get all image files and subsample to 1/5\n",
    "all_files = get_image_files(DATASET_PATH)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "subset_idx = np.random.choice(len(all_files), len(all_files) // 5, replace=False)\n",
    "subset_files = [all_files[i] for i in sorted(subset_idx)]\n",
    "subset_labels = [parent_label(f) for f in subset_files]\n",
    "\n",
    "print(f\"Using {len(subset_files)}/{len(all_files)} images (1/5 subset)\")\n",
    "\n",
    "dls = ImageDataLoaders.from_lists(\n",
    "    DATASET_PATH,\n",
    "    subset_files,\n",
    "    subset_labels,\n",
    "    valid_pct=0.15,\n",
    "    seed=RANDOM_SEED,\n",
    "    item_tfms=Resize(IMAGE_SIZE[0]),\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(\n",
    "            size=IMAGE_SIZE[0],\n",
    "            flip_vert=False,\n",
    "            max_rotate=10.0,\n",
    "            max_lighting=0.2,\n",
    "            max_warp=0.0,\n",
    "            p_affine=0.5,\n",
    "            p_lighting=0.5\n",
    "        ),\n",
    "        Normalize.from_stats(*imagenet_stats)\n",
    "    ],\n",
    "    bs=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# Get class names from the dataloader\n",
    "CLASS_NAMES = list(dls.vocab)\n",
    "\n",
    "print(f\"Classes: {CLASS_NAMES}\")\n",
    "print(f\"Training: {len(dls.train_ds)} images\")\n",
    "print(f\"Validation: {len(dls.valid_ds)} images\")\n",
    "print(f\"Using {NUM_WORKERS} worker threads for data loading\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T15:23:19.076403Z",
     "start_time": "2025-12-28T15:23:18.025820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display sample images organised by task class\n",
    "fig, axes = plt.subplots(len(CLASS_NAMES), 4, figsize=(10, 1.5 * len(CLASS_NAMES)))\n",
    "\n",
    "for row, class_name in enumerate(CLASS_NAMES):\n",
    "    class_path = Path(DATASET_PATH) / class_name\n",
    "    sample_images = list(class_path.ls())[:4]\n",
    "    \n",
    "    for col, img_path in enumerate(sample_images):\n",
    "        axes[row, col].imshow(PILImage.create(img_path))\n",
    "        axes[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[row, col].text(-0.1, 0.5, class_name, \n",
    "                              transform=axes[row, col].transAxes,\n",
    "                              fontsize=10, fontweight='bold', \n",
    "                              ha='right', va='center')\n",
    "\n",
    "plt.subplots_adjust(left=0.15, right=1.0, hspace=0.02, wspace=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T15:25:18.002523Z",
     "start_time": "2025-12-28T15:23:19.090281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create vision learner with ResNet50\n",
    "learn = vision_learner(\n",
    "    dls, \n",
    "    resnet50, \n",
    "    metrics=[accuracy, error_rate],\n",
    "    loss_func=CrossEntropyLossFlat()\n",
    ")\n",
    "\n",
    "# Enable mixed precision training for faster GPU training\n",
    "if USE_MIXED_PRECISION and torch.cuda.is_available():\n",
    "    learn = learn.to_fp16()\n",
    "    print(\"Mixed precision training enabled (FP16)\")\n",
    "\n",
    "# Train!\n",
    "print(\"Training with FastAI...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Workers: {NUM_WORKERS}\")\n",
    "learn.fine_tune(NUM_EPOCHS, base_lr=LEARNING_RATE, freeze_epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMAINING_EPOCHS = 11  # Adjust based on how many epochs you've completed\n",
    "\n",
    "# print(f\"Resuming training for {REMAINING_EPOCHS} more epochs...\")\n",
    "# learn.fit_one_cycle(REMAINING_EPOCHS, lr_max=LEARNING_RATE)\n",
    "# print(\"Training completed\")\n",
    "learn.path = Path(\".\")\n",
    "learn.export(os.path.join(MODEL_DIR,\n",
    "\"task_classifier.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T13:59:13.753985Z",
     "start_time": "2025-12-28T13:48:30.131742Z"
    }
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_model_path = os.path.join(MODEL_DIR, \"task_classifier.pkl\")\n",
    "learn.export(fastai_model_path)\n",
    "print(f\"Model exported: {fastai_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validaiton predictions using FastAI learner\n",
    "preds, targets = learn.get_preds(dl=dls.valid)\n",
    "pred_labels = preds.argmax(dim=1).numpy()\n",
    "true_labels = targets.numpy()\n",
    "\n",
    "val_acc = accuracy_score(true_labels, pred_labels)\n",
    "print(f\"Validation Accuracy: {100*val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_labels, pred_labels, target_names=CLASS_NAMES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot confusion matrix using fastai\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(10, 8), dpi=80)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
